---
abstract: 'As large language models (LLMs) continue to advance, their capacity to
  function effectively across a diverse range of languages has shown marked improvement.
  Preliminary studies observe that the hidden activations of LLMs often resemble English,
  even when responding to non-English prompts. This has led to the widespread assumption
  that LLMs may "think" in English. However, more recent results showing strong multilingual
  performance, even surpassing English performance on specific tasks in other languages,
  challenge this view. In this work, we find that LLMs progressively develop a core
  language-agnostic parameter space-a remarkably small subset of parameters whose
  deactivation results in significant performance degradation across all languages.
  This compact yet critical set of parameters underlies the model''s ability to generalize
  beyond individual languages, supporting the emergence of abstract thought that is
  not tied to any specific linguistic system. Specifically, we identify language-related
  neurons-those are consistently activated during the processing of particular languages,
  and categorize them as either shared (active across multiple languages) or exclusive
  (specific to one). As LLMs undergo continued development over time, we observe a
  marked increase in both the proportion and functional importance of shared neurons,
  while exclusive neurons progressively diminish in influence. These shared neurons
  constitute the backbone of the core language-agnostic parameter space, supporting
  the emergence of abstract thought. Motivated by these insights, we propose neuron-specific
  training strategies tailored to LLMs'' language-agnostic levels at different development
  stages. Experiments across diverse LLM families support our approach.

  '
authors: Yuxin Chen, Yiran Zhao, Yang Zhang, Kenji Kawaguchi An Zhang, Shafiq Joty,
  Junnan Li, Tat-Seng Chua, Michael Qizhe, and Wenxuan Zhang
bibtex: "@inproceedings{Yiran25-NIPS,\n abstract = {As large language models (LLMs)\
  \ continue to advance, their capacity to function effectively across a diverse range\
  \ of languages has shown marked improvement. Preliminary studies observe that the\
  \ hidden activations of LLMs often resemble English, even when responding to non-English\
  \ prompts. This has led to the widespread assumption that LLMs may \"think\" in\
  \ English. However, more recent results showing strong multilingual performance,\
  \ even surpassing English performance on specific tasks in other languages, challenge\
  \ this view. In this work, we find that LLMs progressively develop a core language-agnostic\
  \ parameter space-a remarkably small subset of parameters whose deactivation results\
  \ in significant performance degradation across all languages. This compact yet\
  \ critical set of parameters underlies the model's ability to generalize beyond\
  \ individual languages, supporting the emergence of abstract thought that is not\
  \ tied to any specific linguistic system. Specifically, we identify language-related\
  \ neurons-those are consistently activated during the processing of particular languages,\
  \ and categorize them as either shared (active across multiple languages) or exclusive\
  \ (specific to one). As LLMs undergo continued development over time, we observe\
  \ a marked increase in both the proportion and functional importance of shared neurons,\
  \ while exclusive neurons progressively diminish in influence. These shared neurons\
  \ constitute the backbone of the core language-agnostic parameter space, supporting\
  \ the emergence of abstract thought. Motivated by these insights, we propose neuron-specific\
  \ training strategies tailored to LLMs' language-agnostic levels at different development\
  \ stages. Experiments across diverse LLM families support our approach.},\n address\
  \ = {San Diego, USA},\n author = {Yuxin Chen and Yiran Zhao and Yang Zhang and An\
  \ Zhang, Kenji Kawaguchi and Shafiq Joty and Junnan Li and Tat-Seng Chua and Michael\
  \ Qizhe Shieh and Wenxuan Zhang},\n booktitle = {2025 Conference on Neural Information\
  \ Processing Systems},\n numpages = {9},\n series = {NeurIPS'25},\n title = {The\
  \ Emergence of Abstract Thought in Large Language Models Beyond Any Language},\n\
  \ url = {https://arxiv.org/abs/2506.09890},\n year = {2025}\n}\n"
booktitle: '2025 Conference on Neural Information Processing Systems (<b>NeurIPS''25</b>)

  '
code: null
doc-url: https://arxiv.org/abs/2506.09890
errata: null
id: Yiran25-NIPS
img: Yiran25-NIPS-fig
layout: singlepaper
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/Yiran25-NIPS-slides.pdf
title: 'The Emergence of Abstract Thought in Large Language Models Beyond Any Language

  '
venue: conference
year: 2025
---

{% include singlepaper.html paper=page %}