---
abstract: 'Existing methods on understanding the capabilities of LLMs in logical reasoning
  rely on binary entailment classification or synthetically derived rationales, which
  are not sufficient for properly assessing model''s capabilities. We present \textitP-FOLIO,
  a human-annotated dataset consisting of diverse and complex reasoning chains for
  a set of realistic logical reasoning stories also written by humans. P-FOLIO is
  collected with an annotation protocol that facilitates humans to annotate well-structured
  natural language proofs for first-order logic reasoning problems in a step-by-step
  manner. The number of reasoning steps in P-FOLIO span from 0 to 20. We further use
  P-FOLIO to evaluate and improve large-language-model (LLM) reasoning capabilities.
  We evaluate LLM reasoning capabilities at a fine granularity via single-step inference
  rule classification, with more diverse inference rules of more diverse and higher
  levels of complexities than previous works. Given that a single model-generated
  reasoning chain could take a completely different path than the human-annotated
  one, we sample multiple reasoning chains from a model and use pass@k metrics for
  evaluating the quality of model-generated reasoning chains. We show that human-written
  reasoning chains significantly boost the logical reasoning capabilities of LLMs
  via many-shot prompting and fine-tuning. Furthermore, fine-tuning Llam3-7B on P-FOLIO
  improves the model performance by 10% or more on three other out-of-domain logical
  reasoning datasets.

  '
authors: SIMENG HAN, Aaron Yu, Rui Shen, Zhenting Qi, Martin Riddell, Wenfei Zhou,
  Yujie Qiao, Yilun Zhao, Semih Yavuz, Ye Liu, Shafiq Joty, Yingbo Zhou, Caiming Xiong,
  Rex Ying, Arman Cohan, and Dragomir Radev
bibtex: "@inproceedings{Han-et-al-arxiv-24,\n abstract = {Existing methods on understanding\
  \ the capabilities of LLMs in logical reasoning rely on binary entailment classification\
  \ or synthetically derived rationales, which are not sufficient for properly assessing\
  \ model's capabilities. We present \\textit{P-FOLIO}, a human-annotated dataset\
  \ consisting of diverse and complex reasoning chains for a set of realistic logical\
  \ reasoning stories also written by humans. P-FOLIO is collected with an annotation\
  \ protocol that facilitates humans to annotate well-structured natural language\
  \ proofs for first-order logic reasoning problems in a step-by-step manner. The\
  \ number of reasoning steps in P-FOLIO span from 0 to 20. We further use P-FOLIO\
  \ to evaluate and improve large-language-model (LLM) reasoning capabilities. We\
  \ evaluate LLM reasoning capabilities at a fine granularity via single-step inference\
  \ rule classification, with more diverse inference rules of more diverse and higher\
  \ levels of complexities than previous works. Given that a single model-generated\
  \ reasoning chain could take a completely different path than the human-annotated\
  \ one, we sample multiple reasoning chains from a model and use pass@k metrics for\
  \ evaluating the quality of model-generated reasoning chains. We show that human-written\
  \ reasoning chains significantly boost the logical reasoning capabilities of LLMs\
  \ via many-shot prompting and fine-tuning. Furthermore, fine-tuning Llam3-7B on\
  \ P-FOLIO improves the model performance by 10% or more on three other out-of-domain\
  \ logical reasoning datasets.},\n address = {Miami, USA},\n author = {SIMENG HAN\
  \ and Aaron Yu and Rui Shen and Zhenting Qi and Martin Riddell and Wenfei Zhou and\
  \ Yujie Qiao and Yilun Zhao and Semih Yavuz and Ye Liu and Shafiq Joty and Yingbo\
  \ Zhou and Caiming Xiong and Rex Ying and Arman Cohan and Dragomir Radev},\n booktitle\
  \ = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language\
  \ Processing},\n publisher = {ACL},\n series = {EMNLP'24 Findings},\n title = {{P-FOLIO:\
  \ Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning\
  \ Chains}},\n url = {https://arxiv.org/abs/2209.00840},\n year = {2024}\n}\n"
booktitle: 'Proceedings of the 2024 Conference on Empirical Methods in Natural Language
  Processing (<b>EMNLP''24 Findings</b>)

  '
code: null
doc-url: https://arxiv.org/abs/2209.00840
errata: null
id: Han-et-al-arxiv-24
img: Han-et-al-arxiv-24-fig
layout: singlepaper
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/Han-et-al-arxiv-24-slides.pdf
title: 'P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written
  Reasoning Chains

  '
venue: conference
year: 2024
---

{% include singlepaper.html paper=page %}