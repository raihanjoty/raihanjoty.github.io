---
abstract: 'Existing approaches to lifelong language learning rely on plenty of labeled
  data for learning a new task, which is hard to obtain in most real scenarios. Considering
  that humans can continually learn new tasks from a handful of examples, we expect
  the models also to be able to generalize well on new few-shot tasks without forgetting
  the previous ones. In this work, we define this more challenging yet practical problem
  as Lifelong Few-shot Language Learning (LFLL) and propose a unified framework for
  it based on prompt tuning of T5. Our framework called LFPT5 takes full advantage
  of PT''s strong few-shot learning ability, and simultaneously trains the model as
  a task solver and a data generator. Before learning a new domain of the same task
  type, LFPT5 generates pseudo (labeled) samples of previously learned domains, and
  later gets trained on those samples to alleviate forgetting of previous knowledge
  as it learns the new domain. In addition, a KL divergence loss is minimized to achieve
  label consistency between the previous and the current model. While adapting to
  a new task type, LFPT5 includes and tunes additional prompt embeddings for the new
  task. With extensive experiments, we demonstrate that LFPT5 can be applied to various
  different types of tasks and significantly outperform previous methods in different
  LFLL settings.

  '
authors: Chengwei Qin, and Shafiq Joty
bibtex: "@inproceedings{Chengwei-et-al-arxiv-22,\n abstract = {Existing approaches\
  \ to lifelong language learning rely on plenty of labeled data for learning a new\
  \ task, which is hard to obtain in most real scenarios. Considering that humans\
  \ can continually learn new tasks from a handful of examples, we expect the models\
  \ also to be able to generalize well on new few-shot tasks without forgetting the\
  \ previous ones. In this work, we define this more challenging yet practical problem\
  \ as Lifelong Few-shot Language Learning (LFLL) and propose a unified framework\
  \ for it based on prompt tuning of T5. Our framework called LFPT5 takes full advantage\
  \ of PT's strong few-shot learning ability, and simultaneously trains the model\
  \ as a task solver and a data generator. Before learning a new domain of the same\
  \ task type, LFPT5 generates pseudo (labeled) samples of previously learned domains,\
  \ and later gets trained on those samples to alleviate forgetting of previous knowledge\
  \ as it learns the new domain. In addition, a KL divergence loss is minimized to\
  \ achieve label consistency between the previous and the current model. While adapting\
  \ to a new task type, LFPT5 includes and tunes additional prompt embeddings for\
  \ the new task. With extensive experiments, we demonstrate that LFPT5 can be applied\
  \ to various different types of tasks and significantly outperform previous methods\
  \ in different LFLL settings.},\n author = {Chengwei Qin and Shafiq Joty},\n booktitle\
  \ = {International Conference on Learning Representations},\n issue = {},\n link\
  \ = {https://openreview.net/forum?id=HCRVf71PMF},\n pages = {},\n series = {ICLR-22},\n\
  \ title = {LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based\
  \ on Prompt Tuning of T5},\n year = {2022}\n}\n"
booktitle: 'International Conference on Learning Representations (<b>ICLR-22</b>)

  '
code: null
doc-url: https://openreview.net/forum?id=HCRVf71PMF
errata: null
id: Chengwei-et-al-arxiv-22
img: Chengwei-et-al-arxiv-22-fig
layout: singlepaper
pages: null
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/Chengwei-et-al-arxiv-22-slides.pdf
title: 'LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on
  Prompt Tuning of T5

  '
venue: conference
year: 2022
---

{% include singlepaper.html paper=page %}