---
abstract: 'The Euclidean space is the familiar space for training neural models and
  performing arithmetic operations. However, many data types inherently possess complex
  geometries, and model training methods involve operating over their latent representations,
  which cannot be effectively captured in the Euclidean space. The hyperbolic space
  provides a more generalized representative geometry to model the hierarchical complexities
  of the tree-like structure of natural language. We propose AdaPT a set of guidelines
  for initialization, parametrization, and training of neural networks, which adapts
  to the dataset and can be used with different manifolds.  AdaPT can be generalized
  over any existing neural network training methodology and leads to more stable training
  without a substantial increase in training time. We apply AdaPT guidelines over
  two state-of-the-art deep learning approaches and empirically demonstrate its effectiveness
  through experiments on three tasks over 12 languages across speech and text. Through
  extensive qualitative analysis, we put forward the applicability of AdaPT as a set
  of guidelines optimally utilizing the manifold geometry, which can be extended to
  various downstream tasks across languages and modalities.

  '
authors: Ramit Sawhney, Megh Thakkar, Vishwa Shah, Shrey Pandit, and Shafiq Joty
bibtex: "@inproceedings{Sawhney-et-al-EACL-24,\n abstract = {The Euclidean space is\
  \ the familiar space for training neural models and performing arithmetic operations.\n\
  However, many data types inherently possess complex geometries, and model training\
  \ methods involve operating over their latent representations, which cannot be effectively\
  \ captured in the Euclidean space. The hyperbolic space provides a more generalized\
  \ representative geometry to model the hierarchical complexities of the tree-like\
  \ structure of natural language. We propose AdaPT a set of guidelines for initialization,\
  \ parametrization, and training of neural networks, which adapts to the dataset\
  \ and can be used with different manifolds.  AdaPT can be generalized over any existing\
  \ neural network training methodology and leads to more stable training without\
  \ a substantial increase in training time. We apply AdaPT guidelines over two state-of-the-art\
  \ deep learning approaches and empirically demonstrate its effectiveness through\
  \ experiments on three tasks over 12 languages across speech and text. Through extensive\
  \ qualitative analysis, we put forward the applicability of AdaPT as a set of guidelines\
  \ optimally utilizing the manifold geometry, which can be extended to various downstream\
  \ tasks across languages and modalities.},\n address = {Mexico City, Mexico},\n\
  \ author = {Ramit Sawhney and Megh Thakkar and Vishwa Shah and Shrey Pandit and\
  \ Shafiq Joty},\n booktitle = {2024 Annual Conference of the North American Chapter\
  \ of the Association for Computational Linguistics},\n issue = {},\n pages = {},\n\
  \ series = {NAACL-24 Findings},\n title = {{AdaPT: A Set of Guidelines for Hyperbolic\
  \ Multimodal Multilingual NLP}},\n url = {https://openreview.net/forum?id=SO_l8Jsa9kc},\n\
  \ year = {2024}\n}\n"
booktitle: '2024 Annual Conference of the North American Chapter of the Association
  for Computational Linguistics (<b>NAACL-24 Findings</b>)

  '
code: null
doc-url: https://openreview.net/forum?id=SO_l8Jsa9kc
errata: null
id: Sawhney-et-al-EACL-24
img: Sawhney-et-al-EACL-24-fig
layout: singlepaper
pages: null
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/Sawhney-et-al-EACL-24-slides.pdf
title: 'AdaPT: A Set of Guidelines for Hyperbolic Multimodal Multilingual NLP

  '
venue: conference
year: 2024
---

{% include singlepaper.html paper=page %}