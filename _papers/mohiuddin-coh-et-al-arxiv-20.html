---
abstract: 'Although coherence modeling has come a long way in developing novel models,
  their evaluation on downstream applications for which they are purportedly developed
  has largely been neglected. With the advancements made by neural approaches in applications
  such as machine translation (MT), summarization and dialog systems, the need for
  coherence evaluation of these tasks is now more crucial than ever. However, coherence
  models are typically evaluated only on synthetic tasks, which may not be representative
  of their performance in downstream applications. To investigate how representative
  the synthetic tasks are of downstream use cases, we conduct experiments on benchmarking
  well-known traditional and neural coherence models on synthetic sentence ordering
  tasks, and contrast this with their performance on three downstream applications:
  coherence evaluation for MT and summarization, and next utterance prediction in
  retrieval-based dialog. Our results demonstrate a weak correlation between the model
  performances in the synthetic tasks and the downstream applications, motivating
  alternate training and evaluation methods for coherence models

  '
authors: Tasnim Mohiuddin*, Prathyusha Jwalapuram*, Xiang Lin*, and Shafiq Joty*
bibtex: "@inproceedings{mohiuddin-coh-et-al-arxiv-20,\n abstract = {Although coherence\
  \ modeling has come a long way in developing novel models, their evaluation on downstream\
  \ applications for which they are purportedly developed has largely been neglected.\
  \ With the advancements made\nby neural approaches in applications such as machine\
  \ translation (MT), summarization and dialog systems, the need for coherence evaluation\
  \ of these tasks is now more crucial than ever. However, coherence models are typically\
  \ evaluated only on synthetic tasks, which may not be representative of their performance\
  \ in downstream applications. To investigate how representative the synthetic tasks\
  \ are of downstream use cases, we conduct experiments on benchmarking well-known\
  \ traditional and neural coherence models on synthetic sentence ordering tasks,\
  \ and contrast this with their performance on three downstream applications: coherence\
  \ evaluation for MT and summarization, and next utterance prediction in retrieval-based\
  \ dialog. Our results demonstrate a weak correlation between the model performances\
  \ in the synthetic tasks and the downstream applications, motivating alternate training\
  \ and evaluation methods for coherence models},\n address = {Kyiv},\n author = {Tasnim\
  \ Mohiuddin* and Prathyusha Jwalapuram* and Xiang Lin* and Shafiq Joty*},\n booktitle\
  \ = {Proceedings of the European Chapter of the ACL},\n numpages = {9},\n pages\
  \ = {x–-x},\n publisher = {ACL},\n series = {EACL'21},\n title = {{Rethinking Coherence\
  \ Modeling: Synthetic vs. Downstream Tasks}},\n url = {https://arxiv.org/abs/2004.14626},\n\
  \ year = {2021}\n}\n"
booktitle: 'Proceedings of the European Chapter of the ACL (<b>EACL''21</b>)

  '
code: null
doc-url: https://arxiv.org/abs/2004.14626
errata: null
id: mohiuddin-coh-et-al-arxiv-20
img: mohiuddin-coh-et-al-arxiv-20-fig
layout: singlepaper
pages: x–-x
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/mohiuddin-coh-et-al-arxiv-20-slides.pdf
title: 'Rethinking Coherence Modeling: Synthetic vs. Downstream Tasks

  '
venue: conference
year: 2021
---

{% include singlepaper.html paper=page %}