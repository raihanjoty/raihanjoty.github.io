---
abstract: 'In this paper, we analyze the impact of different automatic annotation
  methods on the performance of supervised approaches to the complex question answering
  problem (defined in the DUC-2007 main task). Huge amount of annotated or labeled
  data is a prerequisite for supervised training. The task of labeling can be accomplished
  either by humans or by computer programs. When humans are employed, the whole process
  becomes time consuming and expensive. So, in order to produce a large set of labeled
  data we prefer the automatic annotation strategy. We apply five different automatic
  annotation techniques to produce labeled data using ROUGE similarity measure, Basic
  Element (BE) overlap, syntactic similarity measure, semantic similarity measure,
  and Extended String Subsequence Kernel (ESSK). The representative supervised methods
  we use are Support Vector Machines (SVM), Conditional Random Fields (CRF), Hidden
  Markov Models (HMM), and Maximum Entropy (MaxEnt). Evaluation results are presented
  to show the impact.

  '
authors: Yllias Chali*, Sadid Hasan*, and Shafiq Joty*
bibtex: "@inproceedings{chali-hasan-joty-acl-09,\n abstract = {In this paper, we analyze\
  \ the impact of\ndifferent automatic annotation methods on the performance of supervised\
  \ approaches to the complex question answering problem (defined in the DUC-2007\
  \ main task). Huge amount of annotated or labeled data is a prerequisite for supervised\
  \ training. The task of labeling can be accomplished either by humans or by computer\
  \ programs. When humans are employed, the whole process becomes time consuming and\
  \ expensive. So, in order to produce a large set of labeled data we prefer the automatic\
  \ annotation strategy. We apply five different automatic annotation techniques to\
  \ produce labeled data using ROUGE similarity measure, Basic Element (BE) overlap,\
  \ syntactic similarity measure, semantic similarity measure, and Extended String\
  \ Subsequence Kernel (ESSK). The representative supervised methods we use are Support\
  \ Vector Machines (SVM), Conditional Random Fields (CRF), Hidden Markov Models (HMM),\
  \ and Maximum Entropy (MaxEnt). Evaluation results are presented to show the impact.},\n\
  \ address = {Suntec, Singapore},\n author = {Chali*, Yllias  and  Hasan*, Sadid\
  \  and  Joty*, Shafiq},\n booktitle = {Proceedings of the ACL-IJCNLP 2009 Conference},\n\
  \ month = {August},\n pages = {329--332},\n publisher = {Association for Computational\
  \ Linguistics},\n series = {ACL'09},\n title = {Do Automatic Annotation Techniques\
  \ Have Any Impact on Supervised Complex Question Answering?},\n url = {http://www.aclweb.org/anthology/P/P09/P09-2083},\n\
  \ year = {2009}\n}\n"
booktitle: 'Proceedings of the ACL-IJCNLP 2009 Conference (<b>ACL''09</b>)

  '
code: null
doc-url: http://www.aclweb.org/anthology/P/P09/P09-2083
errata: null
id: chali-hasan-joty-acl-09
img: chali-hasan-joty-acl-09-fig
layout: singlepaper
pages: 329-332
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/chali-hasan-joty-acl-09-slides.pdf
title: 'Do Automatic Annotation Techniques Have Any Impact on Supervised Complex Question
  Answering?

  '
venue: conference
year: 2009
---

{% include singlepaper.html paper=page %}