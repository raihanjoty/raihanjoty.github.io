---
abstract: 'Large-scale pre-trained language models have shown outstanding performance
  in a variety of NLP tasks. However, they are also known to be significantly brittle
  against specifically crafted adversarial examples, leading to increasing interest
  in probing the adversarial robustness of NLP systems. We introduce RSMI, a novel
  two-stage framework that combines randomized smoothing (RS) with masked inference
  (MI) to improve the adversarial robustness of NLP systems. RS transforms a classifier
  into a smoothed classifier to obtain robust representations, whereas MI forces a
  model to exploit the surrounding context of a masked token in an input sequence.
  RSMI improves adversarial robustness by 2 to 3 times over existing state-of-the-art
  methods on benchmark datasets. We also perform in-depth qualitative analysis to
  validate the effectiveness of the different stages of RSMI and probe the impact
  of its components through extensive ablations. By empirically proving the stability
  of RSMI, we put it forward as a practical method to robustly train large-scale NLP
  models. Our code and datasets are available at https://anonymous.4open.science/r/RSMI.

  '
authors: Han Cheol, Shafiq Joty, Ruochen Zhao, Megh Thakkar, and Chi Xu
bibtex: "@inproceedings{Moon-acl-23,\n abstract = {Large-scale pre-trained language\
  \ models have shown outstanding performance in a variety of NLP tasks. However,\
  \ they are also known to be significantly brittle against specifically crafted adversarial\
  \ examples, leading to increasing interest in probing the adversarial robustness\
  \ of NLP systems. We introduce RSMI, a novel two-stage framework that combines randomized\
  \ smoothing (RS) with masked inference (MI) to improve the adversarial robustness\
  \ of NLP systems. RS transforms a classifier into a smoothed classifier to obtain\
  \ robust representations, whereas MI forces a model to exploit the surrounding context\
  \ of a masked token in an input sequence. RSMI improves adversarial robustness by\
  \ 2 to 3 times over existing state-of-the-art methods on benchmark datasets. We\
  \ also perform in-depth qualitative analysis to validate the effectiveness of the\
  \ different stages of RSMI and probe the impact of its components through extensive\
  \ ablations. By empirically proving the stability of RSMI, we put it forward as\
  \ a practical method to robustly train large-scale NLP models. Our code and datasets\
  \ are available at https://anonymous.4open.science/r/RSMI.},\n address = {Toronto,\
  \ Canada},\n author = {Han Cheol Moon and Shafiq Joty and Ruochen Zhao and Megh\
  \ Thakkar and Chi Xu},\n booktitle = {Proceedings of the 61st Annual Meeting of\
  \ the Association for Computational Linguistics},\n publisher = {ACL},\n series\
  \ = {ACL'23},\n title = {Randomized Smoothing with Masked Inference for Adversarially\
  \ Robust Text Classification},\n url = {https://arxiv.org/abs/2305.06522},\n year\
  \ = {2023}\n}\n"
booktitle: 'Proceedings of the 61st Annual Meeting of the Association for Computational
  Linguistics (<b>ACL''23</b>)

  '
code: null
doc-url: https://arxiv.org/abs/2305.06522
errata: null
id: Moon-acl-23
img: Moon-acl-23-fig
layout: singlepaper
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/Moon-acl-23-slides.pdf
title: 'Randomized Smoothing with Masked Inference for Adversarially Robust Text Classification

  '
venue: conference
year: 2023
---

{% include singlepaper.html paper=page %}