---
abstract: 'Neural Module Networks (NMNs) have been quite successful in incorporating
  explicit reasoning as learnable modules in various question answering tasks, including
  the most generic form of numerical reasoning over text in Machine Reading Comprehension
  (MRC). However, to achieve this, contemporary NMNs need strong supervision in executing
  the query as a specialized program over reasoning modules and fail to generalize
  to more open-ended settings without such supervision. Hence we propose Weakly-Supervised
  Neuro-Symbolic Module Network (WNSMN) trained with answers as the sole supervision
  for numerical reasoning based MRC. It learns to execute a noisy heuristic program
  obtained from the dependency parsing of the query, as discrete actions over both
  neural and symbolic reasoning modules and trains it end-to-end in a reinforcement
  learning framework with discrete reward from answer matching. On the numerical-answer
  subset of DROP, WNSMN outperforms NMN by 32% and the reasoning-free language model
  GenBERT by 8% in exact match accuracy when trained under comparable weak supervised
  settings. This showcases the effectiveness and generalizability of modular networks
  that can handle explicit discrete reasoning over noisy programs in an end-to-end
  manner.

  '
authors: Amrita Saha, Shafiq Joty, and Steven Hoi
bibtex: "@inproceedings{Saha-aaai-2022,\n abstract = {Neural Module Networks (NMNs)\
  \ have been quite successful in incorporating explicit reasoning as learnable modules\
  \ in various question answering tasks, including\nthe most generic form of numerical\
  \ reasoning over text in Machine Reading Comprehension (MRC). However, to achieve\
  \ this, contemporary NMNs need strong supervision in executing the query as a specialized\
  \ program over reasoning modules and fail to generalize to more open-ended settings\
  \ without such supervision. Hence we propose Weakly-Supervised Neuro-Symbolic Module\
  \ Network (WNSMN) trained with answers as the sole supervision for numerical reasoning\
  \ based MRC. It learns to execute a noisy heuristic program obtained from the dependency\
  \ parsing of the query, as discrete actions over both neural and symbolic reasoning\
  \ modules and trains it end-to-end in a reinforcement learning framework with discrete\
  \ reward from answer matching. On the numerical-answer subset of DROP, WNSMN outperforms\
  \ NMN by 32% and the reasoning-free language model GenBERT by 8% in exact match\
  \ accuracy when trained under comparable weak supervised settings. This showcases\
  \ the effectiveness and generalizability of modular networks that can handle explicit\
  \ discrete reasoning over noisy programs in an end-to-end manner.},\n address =\
  \ {Vancouver, Canada},\n author = {Amrita Saha and Shafiq Joty and Steven Hoi},\n\
  \ booktitle = {In Thirty-Sixth AAAI Conference on Artificial Intelligence},\n link\
  \ = {https://arxiv.org/pdf/2101.11802.pdf},\n pages = {},\n series = {AAAI'22},\n\
  \ title = {Weakly Supervised Neuro-Symbolic Module Networks for Numerical Reasoning},\n\
  \ year = {2022}\n}\n"
booktitle: 'In Thirty-Sixth AAAI Conference on Artificial Intelligence (<b>AAAI''22</b>)

  '
code: null
doc-url: https://arxiv.org/pdf/2101.11802.pdf
errata: null
id: Saha-aaai-2022
img: Saha-aaai-2022-fig
layout: singlepaper
pages: null
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/Saha-aaai-2022-slides.pdf
title: 'Weakly Supervised Neuro-Symbolic Module Networks for Numerical Reasoning

  '
venue: conference
year: 2022
---

{% include singlepaper.html paper=page %}