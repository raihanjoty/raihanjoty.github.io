---
abstract: 'Upon its release in late 2022, ChatGPT has brought a seismic shift in the
  entire landscape of AI, both in research and commerce. Through instruction-tuning
  a large language model (LLM) with supervised fine-tuning and reinforcement learning
  from human feedback, it showed that a model could answer human questions and follow
  instructions on a broad panel of tasks. Following this success, interests in LLMs
  have intensified, with new LLMs flourishing at frequent interval across academia
  and industry, including many start-ups focused on LLMs. While closed-source LLMs
  (e.g., OpenAI''s GPT, Anthropic''s Claude) generally outperform their open-source
  counterparts, the progress on the latter has been rapid with claims of achieving
  parity or even better on certain tasks. This has crucial implications not only on
  research but also on business. In this work, on the first anniversary of ChatGPT,
  we provide an exhaustive overview of this success, surveying all tasks where an
  open-source LLM has claimed to be on par or better than ChatGPT.

  '
authors: Hailin Chen, Fangkai Jiao, Xingxuan Li, Chengwei Qin, Mathieu Ravaut, Ruochen
  Zhao, Caiming Xiong, and Shafiq Joty
bibtex: "@inproceedings{Chen-et-al-arxiv-24,\n abstract = {Upon its release in late\
  \ 2022, ChatGPT has brought a seismic shift in the entire landscape of AI, both\
  \ in research and commerce. Through instruction-tuning a large language model (LLM)\
  \ with supervised fine-tuning and reinforcement learning from human feedback, it\
  \ showed that a model could answer human questions and follow instructions on a\
  \ broad panel of tasks. Following this success, interests in LLMs have intensified,\
  \ with new LLMs flourishing at frequent interval across academia and industry, including\
  \ many start-ups focused on LLMs. While closed-source LLMs (e.g., OpenAI's GPT,\
  \ Anthropic's Claude) generally outperform their open-source counterparts, the progress\
  \ on the latter has been rapid with claims of achieving parity or even better on\
  \ certain tasks. This has crucial implications not only on research but also on\
  \ business. In this work, on the first anniversary of ChatGPT, we provide an exhaustive\
  \ overview of this success, surveying all tasks where an open-source LLM has claimed\
  \ to be on par or better than ChatGPT.},\n address = {Arxiv},\n author = {Hailin\
  \ Chen and Fangkai Jiao and Xingxuan Li and Chengwei Qin and Mathieu Ravaut and\
  \ Ruochen Zhao and Caiming Xiong and Shafiq Joty},\n booktitle = {Arxiv},\n publisher\
  \ = {Arxiv},\n series = {cs.CL},\n title = {{ChatGPT's One-year Anniversary: Are\
  \ Open-Source Large Language Models Catching up?}},\n url = {https://arxiv.org/abs/2311.16989},\n\
  \ year = {2024}\n}\n"
booktitle: 'Arxiv (<b>cs.CL</b>)

  '
code: null
doc-url: https://arxiv.org/abs/2311.16989
errata: null
id: Chen-et-al-arxiv-24
img: Chen-et-al-arxiv-24-fig
layout: singlepaper
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/Chen-et-al-arxiv-24-slides.pdf
title: 'ChatGPT''s One-year Anniversary: Are Open-Source Large Language Models Catching
  up?

  '
venue: conference
year: 2024
---

{% include singlepaper.html paper=page %}