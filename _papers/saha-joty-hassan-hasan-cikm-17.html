---
abstract: 'Vector representation of sentences is important for many text processing
  tasks that involve classifying, clustering, or ranking sentences. For solving these
  tasks, bag-of-word based representation has been used for a long time. In recent
  years, distributed representation of sentences learned by neural models from unlabeled
  data has been shown to outperform traditional bag-of-words representations. However,
  most existing methods belonging to the neural models consider only the content of
  a sentence, and disregard its relations with other sentences in the context. In
  this paper, we first characterize two types of contexts depending on their scope
  and utility. We then propose two approaches to incorporate  contextual information
  into content-based models. We evaluate our sentence representation models in a setup,
  where context is available to infer sentence vectors. Experimental results demonstrate
  that our proposed models outshine existing models on three fundamental tasks, such
  as, classifying, clustering, and ranking sentences.

  '
authors: Tanay Saha, Shafiq Joty, Naeemul Hassan, and Mohammad Hasan
bibtex: "@inproceedings{saha-joty-hassan-hasan-cikm-17,\n abstract = {Vector representation\
  \ of sentences is important for many text processing tasks that involve classifying,\
  \ clustering, or ranking sentences. For solving these tasks, bag-of-word based\n\
  representation has been used for a long time. In recent years, distributed representation\
  \ of sentences learned by neural models from unlabeled data has been shown to outperform\
  \ traditional bag-of-words representations. However, most existing methods belonging\
  \ to the neural models consider only the content of a sentence, and disregard its\
  \ relations with other sentences in the context. In this paper, we first characterize\
  \ two types of contexts depending on their scope and utility. We then propose two\
  \ approaches to incorporate  contextual information into content-based models. We\
  \ evaluate our sentence representation models in a setup, where context is available\
  \ to infer sentence vectors. Experimental results demonstrate that our proposed\
  \ models outshine existing models on three fundamental tasks, such as, classifying,\
  \ clustering, and ranking sentences.},\n address = {Singapore},\n author = {Tanay\
  \ Saha and Shafiq Joty and Naeemul Hassan and Mohammad Hasan},\n booktitle = {Proceedings\
  \ of the 26th ACM International Conference on Information and Knowledge Management},\n\
  \ link = {papers/saha-joty-hassan-hasan-cikm-17.pdf},\n month = {November},\n pages\
  \ = {xx--xx},\n publisher = {ACM},\n series = {CIKM'17},\n title = {Regularized\
  \ and Retrofitted models for Learning Sentence Representation with Context},\n year\
  \ = {2017}\n}\n"
booktitle: 'Proceedings of the 26th ACM International Conference on Information and
  Knowledge Management (CIKM''17)

  '
code: null
doc-url: saha-joty-hassan-hasan-cikm-17.pdf
errata: null
id: saha-joty-hassan-hasan-cikm-17
img: saha-joty-hassan-hasan-cikm-17-fig
layout: singlepaper
pages: xx-xx
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/saha-joty-hassan-hasan-cikm-17-slides.pdf
title: 'Regularized and Retrofitted models for Learning Sentence Representation with
  Context

  '
venue: conference
year: 2017
---

{% include singlepaper.html paper=page %}