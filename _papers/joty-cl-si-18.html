---
abstract: 'Participants in asynchronous conversations (e.g., forums, emails) interact
  with each other at different times, performing certain communicative acts, called
  speech acts (e.g., question, request). In this article, we propose a hybrid approach
  to speech act recognition in asynchronous conversations. Our approach works in two
  main steps: a long short-term memory recurrent neural network (LSTM-RNN) first encodes
  each sentence separately into a task-specific distributed representation, which
  is then used in a conditional random field (CRF) model to capture the conversational
  dependencies between sentences. The LSTM-RNN uses pretrained word embeddings learned
  from a large conversational corpus and is trained to classify sentences into speech
  act types. The CRF model can consider arbitrary graph structures to model conversational
  dependencies in an asynchronous conversation. In addition, to mitigate the problem
  of limited annotated data in the asynchronous domains, we adapt the LSTM-RNN model
  to learn from synchronous conversations (e.g., meetings) using domain adversarial
  training of neural networks. Empirical evaluation shows the effectiveness of our
  approach over existing ones: (i) LSTM-RNNs provide better task-specific representations,
  (ii) conversational word embeddings benefit the LSTM-RNNs more than the off-the-shelf
  ones, (iii) adversarial training gives better domain-invariant representations,
  and (iv) the global CRF model improves over local models.

  '
authors: Shafiq Joty, and Tasnim Mohiuddin
bibtex: "@article{joty-cl-si-18,\n abstract = {Participants in asynchronous conversations\
  \ (e.g., forums, emails) interact with each other at\ndifferent times, performing\
  \ certain communicative acts, called speech acts (e.g., question, request). In this\
  \ article, we propose a hybrid approach to speech act recognition in asynchronous\
  \ conversations. Our approach works in two main steps: a long short-term memory\
  \ recurrent neural network (LSTM-RNN) first encodes each sentence separately into\
  \ a task-specific distributed representation, which is then used in a conditional\
  \ random field (CRF) model to capture the conversational dependencies between sentences.\
  \ The LSTM-RNN uses pretrained word embeddings learned from a large conversational\
  \ corpus and is trained to classify sentences into speech act types. The CRF model\
  \ can consider arbitrary graph structures to model conversational dependencies in\
  \ an asynchronous conversation. In addition, to mitigate the problem of limited\
  \ annotated data in the asynchronous domains, we adapt the LSTM-RNN model to learn\
  \ from synchronous conversations (e.g., meetings) using domain adversarial training\
  \ of neural networks. Empirical evaluation shows the effectiveness of our approach\
  \ over existing ones: (i) LSTM-RNNs provide better task-specific representations,\
  \ (ii) conversational word embeddings benefit the LSTM-RNNs more than the off-the-shelf\
  \ ones, (iii) adversarial training gives better domain-invariant representations,\
  \ and (iv) the global CRF model improves over local models.},\n author = {Shafiq\
  \ Joty and Tasnim Mohiuddin},\n journal = {Computational Linguistics (Special Issue\
  \ on Language in Social Media, Exploiting discourse and other contextual information)},\n\
  \ link = {https://www.mitpressjournals.org/doi/pdf/10.1162/coli_a_00339},\n number\
  \ = {4},\n pages = {859 -- 894},\n publisher = {MIT Press},\n title = {Speech Act\
  \ Modeling of Written Asynchronous Conversations: A Neural CRF Approach},\n volume\
  \ = {44},\n year = {2018}\n}\n"
code: null
doc-url: https://www.mitpressjournals.org/doi/pdf/10.1162/coli_a_00339
errata: null
id: joty-cl-si-18
img: joty-cl-si-18-fig
journal: Computational Linguistics (Special Issue on Language in Social Media, Exploiting
  discourse and other contextual information)
layout: singlepaper
pages: 859 - 894
paper-type: article
picture: shafiq
selected: true
slides: null
title: 'Speech Act Modeling of Written Asynchronous Conversations: A Neural CRF Approach

  '
venue: journal
year: 2018
---

{% include singlepaper.html paper=page %}