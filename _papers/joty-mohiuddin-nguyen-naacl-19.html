---
abstract: 'We address the problem of speech act recognition (SAR) in asynchronous
  conversations (e.g., forums, emails). However, unlike synchronous conversations
  (e.g., meetings, phone), asynchronous domains lack large labeled datasets to train
  an effective SAR model. In this paper, we propose methods to effectively leverage
  abundant unlabeled conversational data and the available labeled data from synchronous
  domains. We carry out our research in three main steps. First, we introduce a neural
  architecture based on hierarchical LSTMs and conditional random fields (CRF) for
  SAR in asynchronous conversations, and show that our method outperforms existing
  methods when trained on in-domain data only. Second, we improve our initial SAR
  models by semi-supervised learning in the form of pretrained word embeddings learned
  from a large unlabeled conversational corpus. Finally, we employ adversarial training
  to improve the results further by leveraging the labeled data from synchronous domains
  and by explicitly modeling the shift in two domains.

  '
authors: Tasnim Mohiuddin, Thanh-Tung Nguyen, and Shafiq Joty
bibtex: "@inproceedings{joty-mohiuddin-nguyen-naacl-19,\n abstract = {We address the\
  \ problem of speech act recognition\n(SAR) in asynchronous conversations (e.g.,\
  \ forums, emails). However, unlike synchronous conversations (e.g., meetings, phone),\
  \ asynchronous domains lack large labeled datasets to train an effective SAR model.\
  \ In this paper, we propose methods to effectively leverage abundant unlabeled conversational\
  \ data and the available labeled data from synchronous domains. We carry out our\
  \ research in three main steps. First, we introduce a neural architecture based\
  \ on hierarchical LSTMs and conditional random fields (CRF) for SAR in asynchronous\
  \ conversations, and show that our method outperforms existing methods when trained\
  \ on in-domain data only. Second, we improve our initial SAR models by semi-supervised\
  \ learning in the form of pretrained word embeddings learned from a large unlabeled\
  \ conversational corpus. Finally, we employ adversarial training to improve the\
  \ results further by leveraging the labeled data from synchronous domains and by\
  \ explicitly modeling the shift in two domains.},\n address = {Minneapolis, USA},\n\
  \ author = {Tasnim Mohiuddin and Thanh-Tung Nguyen and Shafiq Joty (equal contributions)},\n\
  \ booktitle = {Proceedings of the North American Chapter of the Association for\
  \ Computational Linguistics: Human Language Technologies},\n link = {https://arxiv.org/abs/1904.04021},\n\
  \ numpages = {9},\n pages = {xx–-xx},\n publisher = {ACL},\n series = {NAACL'19},\n\
  \ title = {Adaptation of Hierarchical Structured Models for Speech Act Recognition\
  \ in Asynchronous Conversation},\n year = {2019}\n}\n"
booktitle: 'Proceedings of the North American Chapter of the Association for Computational
  Linguistics: Human Language Technologies (NAACL''19)

  '
code: null
doc-url: https://arxiv.org/abs/1904.04021
errata: null
id: joty-mohiuddin-nguyen-naacl-19
img: joty-mohiuddin-nguyen-naacl-19-fig
layout: singlepaper
pages: xx–-xx
paper-type: inproceedings
picture: shafiq
selected: false
slides: media/joty-mohiuddin-nguyen-naacl-19-slides.pdf
title: 'Adaptation of Hierarchical Structured Models for Speech Act Recognition in
  Asynchronous Conversation

  '
venue: conference
year: 2019
---

{% include singlepaper.html paper=page %}